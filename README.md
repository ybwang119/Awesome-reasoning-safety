# Awesome-reasoning-safety
## Attacks
Adversarial Reasoning at Jailbreaking Time

THE DARK DEEP SIDE OF DEEPSEEK: FINE-TUNING ATTACKS AGAINST THE SAFETY ALIGNMENT OF COT-ENABLED MODELS

OVERTHINK: Slowdown Attacks on Reasoning LLMs

## Defenses
GuardReasoner: Towards Reasoning-based LLM Safeguards


## Studies
TRADING INFERENCE-TIME COMPUTE FOR ADVERSARIAL ROBUSTNESS.
## Surveys, Datasets and Benchmarks
